{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting Google Drive\n",
        "\n",
        " Mounting Google Drive for accessing files"
      ],
      "metadata": {
        "id": "8O2O6sroHaRs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFtK9yfJztf1",
        "outputId": "fb53874b-7af8-494a-ad63-4977bc863e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Environment Variables\n",
        "Setting environment variables to control PyTorch's CUDA memory allocation."
      ],
      "metadata": {
        "id": "aixxAPObHi4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:50'"
      ],
      "metadata": {
        "id": "-PaPidmlHS50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the Data\n",
        "\n",
        "Preprocessing the text data by splitting it into sections based on 'CHAPTER' and removing any whitespace.\n"
      ],
      "metadata": {
        "id": "WX9xXAKbHt-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(text):\n",
        "    sections = text.split('CHAPTER')\n",
        "    processed_sections = [section.strip() for section in sections if section.strip() != '']\n",
        "    return processed_sections\n",
        "\n",
        "# Read the text file and preprocess\n",
        "with open('/content/drive/MyDrive/LegalDocs/usc45.xml', 'r', encoding='utf-8') as file:\n",
        "    text_data = file.read()\n",
        "\n",
        "processed_data = preprocess_data(text_data)"
      ],
      "metadata": {
        "id": "NpvdMEexNJP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the BART Model for Summary Generation\n",
        "\n",
        "Loading the pre-trained BART model and tokenizer from Hugging Face for generating summaries.\n"
      ],
      "metadata": {
        "id": "ZM4EpEZGHyPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "# Load BART model and tokenizer for summary generation\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n"
      ],
      "metadata": {
        "id": "6Tyyrd-x0Ils"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating and Saving Summaries\n",
        "\n",
        "Generating summaries for the processed data using the BART model and save them to your Google Drive.\n"
      ],
      "metadata": {
        "id": "RZxGvKhyH2qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text):\n",
        "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
        "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Generate summaries\n",
        "output_texts = [generate_summary(text) for text in processed_data]\n",
        "\n",
        "# Save summaries\n",
        "output_file_path = '/content/drive/MyDrive/LegalDocs/generatedSummaries.txt'\n",
        "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "    for summary in output_texts:\n",
        "        file.write(summary + '\\n')\n"
      ],
      "metadata": {
        "id": "Yvs6QdRl0JLb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Saved Summaries\n",
        "Reading the previously saved summaries from a file in Google Drive."
      ],
      "metadata": {
        "id": "lZSOHJaPH85W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path for the existing summaries\n",
        "output_file_path = '/content/drive/MyDrive/LegalDocs/generated_summaries.txt'\n",
        "\n",
        "# Read the summaries from the file\n",
        "output_texts = []\n",
        "with open(output_file_path, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        output_texts.append(line.strip())  # Append each summary to the list"
      ],
      "metadata": {
        "id": "eQOcPXM_GxWP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting Data for Training and Validation\n",
        "\n",
        "Splitting the dataset into training and validation sets and tokenize the data."
      ],
      "metadata": {
        "id": "cDeBV_ZKIHMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BartTokenizer\n",
        "import torch\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_inputs, val_inputs, train_outputs, val_outputs = train_test_split(\n",
        "    processed_data, output_texts, test_size=0.1\n",
        ")\n",
        "\n",
        "# Tokenize the data\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
        "train_input_encodings = tokenizer(train_inputs, truncation=True, padding='max_length', max_length=256)\n",
        "train_output_encodings = tokenizer(train_outputs, truncation=True, padding='max_length', max_length=512)\n",
        "val_input_encodings = tokenizer(val_inputs, truncation=True, padding='max_length', max_length=512)\n",
        "val_output_encodings = tokenizer(val_outputs, truncation=True, padding='max_length', max_length=512)\n",
        "\n",
        "# Define custom dataset class\n",
        "class RailroadsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = RailroadsDataset(train_input_encodings, train_output_encodings)\n",
        "val_dataset = RailroadsDataset(val_input_encodings, val_output_encodings)\n"
      ],
      "metadata": {
        "id": "TzhVaa8h0LfH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Custom Dataset Class\n",
        "\n",
        "Defining a custom PyTorch dataset class for handling the tokenized data."
      ],
      "metadata": {
        "id": "9FViRi0yIOas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, TrainingArguments, Trainer\n",
        "\n",
        "# Load the BART model\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/LegalDocs/results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='/content/drive/MyDrive/LegalDocs/logs'\n",
        ")\n"
      ],
      "metadata": {
        "id": "KFGR1RjNB1Tf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Training and Validation Datasets\n",
        "\n",
        "Creating instances of the custom dataset for both training and validation."
      ],
      "metadata": {
        "id": "Deg_2txIISve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "model.save_pretrained('/content/drive/MyDrive/LegalDocs/fine_tuned_BART_railroads')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "G7regj3m0M1y",
        "outputId": "1ec74844-1d40-45e0-8529-9b9fc93941bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [96/96 01:17, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Fine-Tuned BART Model\n",
        "This cell loads the fine-tuned BART model and tokenizer. The model is used for generating summaries from text.\n"
      ],
      "metadata": {
        "id": "fDdUuDY1Euqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "# Load the fine-tuned model\n",
        "model = BartForConditionalGeneration.from_pretrained('/content/drive/MyDrive/LegalDocs/fine_tuned_BART_railroads')\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n"
      ],
      "metadata": {
        "id": "xdsIx8t6EtZl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Summary Function\n",
        "This function uses the loaded BART model to generate a summary for a given piece of text. The function takes the text, model, tokenizer, and maximum lengths for input and output as parameters.\n"
      ],
      "metadata": {
        "id": "p01VZbKPJoaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text, model, tokenizer, max_input_length=1024, max_output_length=150):\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=max_input_length, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=max_output_length, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "Z1aBFs8VExfV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the Summary Generation\n",
        "Here we test the summary generation function by providing a new text snippet. The generated summary is then printed.\n"
      ],
      "metadata": {
        "id": "jM7H3HfkJsLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"Vacancies in membership or office shall be filled, members shall be appointed in case of failure of the carriers or of labor organizations of the employees to select and designate representatives, members of the National Air Transport Adjustment Board shall be compensated, hearings shall be held, findings and awards made, stated, served, and enforced, and the number and compensation of any necessary assistants shall be determined and the compensation of such employees shall be paid, all in the same manner and to the same extent as provided with reference to the National Railroad Adjustment Board by section 153 of this title. The powers and duties prescribed and established by the provisions of section 153 of this title with reference to the National Railroad Adjustment Board and the several divisions thereof are conferred upon and shall be exercised and performed in like manner and to the same extent by the said National Air Transport Adjustment Board, not exceeding, however, the jurisdiction conferred upon said National Air Transport Adjustment Board by the provisions of this subchapter. \"\n",
        "summary = generate_summary(new_text, model, tokenizer)\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN76QIQJEyp0",
        "outputId": "fec6611d-1c7e-45a5-eda4-591aca3f3c84"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summarize:  Vacancies in membership or office shall be filled, members shall be appointed in case of failure of the carriers or of labor organizations of the employees to select and designate representatives, members of the National Air Transport Adjustment Board shall be compensated, hearings shall be held, findings and awards made, stated, served, and enforced, and the number and compensation of any necessary assistants shall be determined and the compensation of such employees shall be paid, all in the same manner and to the same extent as provided with reference to the National Railroad Adjustment board by section 153 of this title. The powers and duties prescribed and established by the provisions of section 153 thereof are conferred upon and shall be exercised and performed by the said National Air\n"
          ]
        }
      ]
    }
  ]
}
